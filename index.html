<!DOCTYPE HTML>
<html>
	<head>
		<title>Max's Portfolio</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
        </head>
	<body class="is-preload">

		<div id="wrapper" class="fade-in">

				<div id="intro">
						<h1>Max Ellis</h1>
						<p>Senior Software Engineer & Problem Solver</p>
						<ul class="actions">
							<li><a href="#header" class="button icon solid solo fa-arrow-down scrolly">Continue</a></li>
						</ul>
					</div>

				<header id="header">
						<p class="logo">Max</p>
					</header>

				<nav id="nav">
						<ul class="links">
							<li class="active"><a href="index.html">Content</a></li>
						</ul>
						<ul class="icons">
							<li><a href="https://github.com/max-ellis" class="icon brands fa-github"><span class="label">Github</span></a></li>
							<li><a href="https://www.linkedin.com/in/max-ellis-cs/" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
						</ul>
					</nav>

				<div id="main">

						<article class="post featured">
								<header class="major">
									<h3>About Me</h3>
									<p>Max Ellis graduated with a Master's degree from the University of Alberta in June 2022. He started working as a Software Engineer at Act-On in November 2022 and quickly found his stride, developing a deep passion for the field. Max constantly seeks opportunities to grow, contribute, and become a better software engineer, viewing his work as a fulfilling hobby.</p>
                                    <p>He brings a unique perspective from his time as a wildland firefighter, ready to roll up his sleeves, adapt to rapidly changing situations, and fight any virtual "fires" that arise. Max is driven by a commitment to build resilient systems and solve complex problems at scale, translating complex challenges into robust engineering solutions.</p>
								</header>
								<a href="#"><img src="images/prof.jpg" alt="" width = "500" height = "500" /></a>
							</article>

						<h2 style ="text-align: center">EDUCATION</h2>
							<article>
								<p><b>M.Sc Computing Science : </b>University of Alberta, Edmonton, Alberta<br />
								<b>Graduation: </b>June 2022 <br/>
								<b>Advisor :</b> Sarah Nadi <br/>
								<b>GPA : </b>4.0/4.0 <br/> </p>
								<p><b>B.Sc Computer Science : </b>Washington State University, Vancouver, Washington<br />
								<b>Graduated : </b>May 2019 <br/>
								<b>GPA : </b>3.92/4.0 </p>
							</article>

						<h2 style ="text-align: center">WORK EXPERIENCE</h2>
                        <section class="posts">
                            <article class="single-column-article">
                                <header>
                                    <span class="date">November 2022 - Present</span>
                                    <h2>Senior Software Engineer, Act-On Software</h2>
                                </header>
                                <p class="image fit"><img src="images/act-on.jpg" alt="Act-On Logo" /></p>
                                <p>
                                    As a Senior Software Engineer at Act-On, I've been instrumental in architecting, developing, and optimizing critical data infrastructure and services, driving significant improvements in performance, reliability, and scalability for our marketing automation platform. My tenure has involved rapid growth and an increasing scope of responsibility, tackling complex engineering challenges and contributing to strategic technical initiatives. I lead projects from design through deployment, ensuring high-quality, maintainable solutions.
                                </p>
                                <ul class="project-details">
                                    [cite_start]<li><strong>End-to-End Feature Development & Integration:</strong> Played a pivotal role in the design, implementation, and deployment of complex features like Act-On’s Custom Objects[cite: 14]. This involved deep dives into customer needs, translating requirements into technical specifications, and building robust integrations to onboard and utilize customer-specific structured data for advanced segmentation and personalization.</li>
                                    <li><strong>High-Throughput Data Pipeline & Real-time Processing:</strong> Architected and implemented a sophisticated, real-time data pipeline capable of handling massive data volumes. [cite_start]This system leverages Apache Kafka for high-throughput message queuing, AWS Snowpipe for efficient streaming data ingestion into Snowflake, and Spring Cloud Data Flow for orchestrating intricate data transformation pipelines[cite: 15], consistently maintaining low latency for critical data pathways.</li>
                                    [cite_start]<li><strong>Data Lake Service Optimization & Reliability:</strong> Led critical initiatives to enhance Act-On’s data infrastructure, specifically stabilizing the Data Lake management service[cite: 17]. [cite_start]By implementing optimized Snowflake deferred merge strategies and refining data indexing, I successfully eliminated persistent data errors (previously over 800 per hour), drastically reduced average response times from 8 minutes to 300 milliseconds, and eradicated data duplication[cite: 17], leading to significant improvements in data integrity and system reliability.</li>
                                    [cite_start]<li><strong>Mission-Critical Service Modernization & Cloud Migration Strategy:</strong> Spearheaded the comprehensive modernization of a legacy, monolithic dataflow service[cite: 18]. [cite_start]This included a significant upgrade from Java 8 to Java 21, resolving complex compatibility issues, and consolidating distributed H2 databases into a centralized PostgreSQL system[cite: 18]. [cite_start]This transformation not only vastly improved service stability and performance but also laid crucial groundwork for, and directly enabled, its seamless migration to AWS cloud environments[cite: 19].</li>
                                    [cite_start]<li><strong>Resilient Cloud Infrastructure Development:</strong> Built and managed core Snowflake and AWS infrastructure (e.g., S3, EC2, ECS, Lambda, RDS) using Infrastructure-as-Code tools like Terraform and Puppet[cite: 10]. My focus was on establishing a foundation for highly resilient, scalable services capable of processing millions of data points, ensuring robust performance and stability in a dynamic production environment.</li>
                                    [cite_start]<li><strong>Proactive Monitoring & Operational Excellence:</strong> Designed and established comprehensive monitoring and alerting systems across key services [cite: 20] to proactively identify and address performance bottlenecks and potential operational issues, ensuring continuous system health and contributing to overall operational excellence.</li>
                                    <li><strong>Technical Leadership & Cross-Functional Collaboration:</strong> Consistently collaborated with project leads, product managers, and other software developers to translate complex product requirements into clear technical designs and resolve challenging architectural problems. [cite_start]I also contributed to team growth by championing customer support escalations, allowing core development teams to focus on strategic initiatives, and by actively mentoring junior developers in testing methodologies and code design principles[cite: 23].</li>
                                </ul>
                            </article>
                            <article>
									<header>
										<span class="date">May 2020 - December 2021</span>
										<h2>Research Assistant, University of Alberta</h2>
									</header>
									 <p class="image fit"><img src="images/SMR.png" alt="" /></p>
									[cite_start]<p><ul><li>Spearheaded a project with an external collaborator to revitalize operation-based refactoring-aware merging, allowing it to be applied in practice with Git. [cite: 26] [cite_start]</li><li>Analyzed experimental data utilizing Python libraries to compare the strengths and weaknesses of two refactoring-aware merging approaches, providing insights and paths forward for each approach. [cite: 27] [cite_start]</li><li>Leveraged sparsely documented third party libraries to programmatically perform refactorings and detect refactoring-related merge conflicts, supporting 17 of the most common known refactoring types. [cite: 28] </li></ul></p>
								</article>
								<article>
									<header>
										<span class="date">September 2019 - May 2020</span>
										<h2>Teaching Assistant, University of Alberta</h2>
									</header>
									<p class="image fit"><img src="images/UofA.JPG" alt="" /></p>
									<p><ul><li>Delivered course material in a lab setting to help students succeed in CMPUT 379 (Operating Systems).</li>
										<li> Presented additional information and answered questions in office hours and online about operating systems and C/C++.</li>
										<li> Designed assessments, quizzes, and exams alongside the instructor to assess the students' mastery of the material.</li></ul> </p>
								</article>
								<article>
									<header>
										<span class="date">April 2016 - May 2019</span>
										<h2>STEM Tutor, Clark College</h2>
									</header>
									 <p class="image fit"><img src="images/Clark.jpg" alt="" /></p>
									<p><ul><li>Assisted students at all levels with STEM fields such as computer science, math, electrical engineering, and more.</li>
										<li>Helped students through a variety of methods to adapt to each student's learning style.</li>
										<li>Fostered a positive and inclusive environment for all students and staff using interpersonal skills.</li></ul></p>
										<p>
										<em>My time as a STEM tutor was a vastly rewarding experience. First and foremost, I was able to help hundreds of students at all levels and in some cases, I got to watch students develop a passion for their field as they advanced through their program. In the process of helping them, I was able to strengthen my own problem solving skills and my computer science fundamentals, as well as developing the ability to help train new team members.</em>
										</p>
								</article>
								<article>
									<header>
										<span class="date">April 2014 - September 2015</span>
										<h2>Wildland Firefighter (Type 2 Initial Attack), GFP Response</h2>

									</header>
									 <p class="image fit"><img src="images/GFP.jpg" alt="" /></p>
									<p><ul><li>Adapted to rapidly changing situations and environments to keep my team and myself safe.</li>
										<li>Completed objectives effectively through teamwork with my team and other teams while under intense pressure to keep the public safe.</li>
										<li>Actively communicated fire behavior with other firefighters and air attack to ensure safe fire engagement.</li></ul></p>

										<p>
										<em> My time as a wildland firefighter taught me valuable skills that are transferrable to computer science positions: Communication and Discipline. I additionally practiced my ability to work under pressure, learned how to manage time effectively, and developed organization skills.</em>
										</p>
								</article>

							</section>


						<h2 style ="text-align: center">SELECT ENGINEERING PROJECTS</h2>
							<section class="posts">
                                <article class="single-column-article">
                                    <header>
                                        <h3>Real-time Data Ingestion & Transformation Platform</h3>
                                    </header>
                                    <p class="image fit"><img src="images/data_pipeline.jpg" alt="Data Pipeline Diagram" /></p>
                                    <p>
                                        Architected and implemented a robust, highly-available data ingestion and transformation platform critical for Act-On's marketing automation services. This system processes millions of customer data points daily, enabling real-time analytics and personalized customer experiences.
                                    </p>
                                    <ul class="project-details">
                                        <li><strong>Core Technologies:</strong> Leveraged Apache Kafka for high-throughput message queuing, AWS Snowpipe for efficient streaming data ingestion into Snowflake, and Spring Cloud Data Flow for orchestrating complex data transformation pipelines.</li>
                                        <li><strong>Scalability & Performance:</strong> Designed the system to dynamically scale with increasing data volumes, consistently maintaining sub-second latency for critical data pathways. Optimized Snowflake queries and data models to ensure efficient processing and retrieval.</li>
                                        <li><strong>Impact:</strong> Directly enabled new product features requiring immediate data availability, improved the accuracy of customer segmentation, and reduced data processing costs by optimizing resource utilization.</li>
                                        <li><strong>Role:</strong> Lead Architect and primary developer for key components of the ingestion and transformation layers.</li>
                                    </ul>
                                </article>

                                <article class="single-column-article">
                                    <header>
                                        <h3>Legacy Service Modernization & Cloud Migration</h3>
                                    </header>
                                    <p class="image fit"><img src="images/modernization.jpg" alt="Code Modernization" /></p>
                                    <p>
                                        Led the comprehensive modernization of a mission-critical, monolithic dataflow service responsible for core marketing automation logic. This initiative was key to improving system stability, performance, and laying groundwork for full cloud migration.
                                    </p>
                                    <ul class="project-details">
                                        <li><strong>Technical Upgrade:</strong> Orchestrated the upgrade of the entire service codebase from Java 8 to Java 21, resolving numerous compatibility issues and leveraging modern language features for improved performance and maintainability.</li>
                                        <li><strong>Database Centralization:</strong> Consolidated disparate, distributed H2 databases into a centralized PostgreSQL system, eliminating data inconsistencies and simplifying database management.</li>
                                        <li><strong>Migration Strategy:</strong> Developed a detailed rollout plan and comprehensive test suite to mitigate risk during the upgrade and database migration, ensuring zero downtime for customers.</li>
                                        <li><strong>Cloud Readiness:</strong> This modernization significantly improved service visibility and reduced its footprint, directly enabling its seamless migration from an on-premise data center to AWS, improving overall operational efficiency and resilience.</li>
                                    </ul>
                                </article>

                                <article class="single-column-article">
                                    <header>
                                        <h3>Data Lake Performance & Reliability Enhancement</h3>
                                    </header>
                                    <p class="image fit"><img src="images/data_lake_optimization.jpg" alt="Data Lake Optimization" /></p>
                                    <p>
                                        Identified and resolved critical stability and performance issues within Act-On's core data lake query service, transforming it from a bottleneck into a highly reliable and efficient data foundation.
                                    </p>
                                    <ul class="project-details">
                                        <li><strong>Problem Identification:</strong> Diagnosed root causes of severe data errors (averaging 800 per hour) and unacceptably slow response times (up to 8 minutes) affecting core customer analytics.</li>
                                        <li><strong>Solution Implementation:</strong> Implemented a Snowflake deferred merge strategy and optimized data indexing techniques, drastically reducing query execution times and eliminating data duplication.</li>
                                        <li><strong>Quantitative Impact:</strong> Reduced average response time from 8 minutes to 300 milliseconds and completely eliminated previously persistent data errors, leading to significantly improved data integrity and user experience.</li>
                                        <li><strong>Tools:</strong> Snowflake, AWS S3, custom data validation scripts.</li>
                                    </ul>
                                </article>
							</section>

						<footer>
								<h2>Resume</h2>
								<button class="w3-button w3-light-grey w3-padding-large w3-section" onclick="window.open('files/Ellis_Max_Resume.pdf')">
     							 <i class="fa fa-download"></i> Download Resume
   								 </button>
							</footer>

					</div>

				<footer id="footer">
						<section class="split contact">
							<section>
								<h3>Email</h3>
								<p>maxjordanellis@gmail.com</p>
							</section>
						</section>
					</footer>

			</div>

		<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>